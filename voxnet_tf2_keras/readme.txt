########################################################################################
lib_IO_hdf5.py
    requires:
        numpy.__version__==1.11.0
        h5py.__version__==2.6.0

    class that helps loading a dataset based on a hdf5 file in the appropriate way,
    provides function to pass the neccessary data to the model_keras voxnet.

    Members:
        Class loader_Convert_to_Np
            def sort_by_rotation
            def shuffle_data
            def validation_split
            def define_max_pos
            def train_generator
            def return_num_train_samples
            def valid_generator
            def return_num_valid_samples
            def evaluate_generator
            def return_num_evaluate_samples
            def change_batch_size
            def change_validation_size
            def return_nb_classes

    Input:
        Type        |   Name                |   Use
        ----------------------------------------------
        string      |   dataset             |   string that leads to dataset
        int         |   batch_size = 128    |   Batch size which will be generated by generator
        bool        |   shuffle             |   option for shuffle
        bool        |   has rotations       |   option to activate rotation shuffle&validsplit
        float[0,1]  |   valid_split         |   size for validation set in percentage of train set


    loading dataset Example:

        loader = lib_IO_hdf5.Loader_hdf5_Convert_Np("data/modelnet10.hdf5",
                                                    batch_size=128,
                                                    shuffle= True,
                                                    has_rot= False,
                                                    valid_split= 0.15)


    Structure of the hdf5 library should be:
    necessary   |    Path                    |   Size of Dataset                 | Use
    --------------------------------------------------------------------------------------------------------
                |    train                   |                                   |
    necessary   |    train/label_train       |   [num samples,]                  |   Training Labels
    necessary   |    train/features_train    |   [num samples, 1, 32, 32, 32]    |   Training Features
                |    train/info_train        |   [num samples, 3]                |   Training (labelID, ObjectID, RotationID)
                |    test                    |                                   |
    necessary   |    train/label_test        |   [num samples,]                  |   Test Labels
    necessary   |    train/features_test     |   [num samples, 1, 32, 32, 32]    |   Test Features
                |    train/info_test         |   [num samples, 3]                |   Test (labelID, ObjectID, RotationID)

    the info datasets allow the loader to perform functions such as batch shuffle and batch validation split
    therefore the Object ID has to be the same for objects that stem from one batch/rotation. meaning hereby
    objects that are from one rotation can be trained immediatly after each other. this rotation batch size is
    independent from the batch size passed to the loader. not neccessary

#################################################################################################
model_keras.py
    requires:
        keras.__version__== 1.0.0
        theano.__version__==0.9.0

    Members:
        def learningRateSchedule
        Class Model_vt
            def __init__
            def fit
            def continue_fit
            def evaluate
            def load_weights
            def predict

    Imput:
        Type                    |   name                |   Use
        --------------------------------------------------------------------------------------------
        int                     |   nb_classes          |   number of classes to train
        string                  |   dataset_name        |   name for saving purpose only
        train_generator         |   generator           |   training samples generator from loader class
        int                     |   samples_per_epoche  |   samples per epoche from loader class
        int                     |   nb_epoche           |   number of epochs to train
        valid_generator         |   valid_generator     |   valid samples generator from loader class
        int                     |   nb_val_samples      |   valid samples der epoch from loader class
        int{0,1,2}              |   verbosity           |   verbosity mode 0=none, 1=some, 2=full
        string                  |   weights_file        |   hdf5 file of voxnet weights
        ndarray [~,1,32,32,32]  |   X_predict           |   voxel array of object for prediction

    example initalize

        voxnet = model_keras.model_vt(nb_classes=loader.return_nb_classes(), dataset_name="modelnet10")

    example fit

        voxnet.fit(generator=loader.train_generator(),
                       samples_per_epoch=loader.return_num_train_samples(),
                       nb_epoch=40,
                       valid_generator=loader.valid_generator(),
                       nb_valid_samples=loader.return_num_valid_samples(),
                       verbosity=2,
                       )


##################################################################################################
run_voxnet_keras.py

    Run_voxnet_keras is a script version of the classes to use shell argument parsing for easier
    training and use with cluster functions like slurm and srun/sbatch

    Example:
        srun /usr/bin/python run_voxnet_keras.py "data/modelnet40.hdf5" --batch=64 --verbosity=2 --epochs=40 --validate=0.0

#################################################################################################
recognizer_voxnet.py
    requires:
        numpy.__version__==1.11.0
        h5py.__version__==0.17.1

        load_pc:
            load point cloud from project tango tabled

        voxelize:
            turn project tango data density grid into voxnet voxel volume

        voxel_scatter:
            function to turn voxel volume into matplot lib scatterplto compatible array

        detector voxnet:
            __init__:
                initialize voxnet from a weights file
            predict:
                predict probabilites and label for an object

        Example:
            Checkout file live_demo.ipynb